{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2beb517-57ac-4473-a0cd-e023fd5dcf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set up environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj\"\n",
    "os.environ[\"NEO4J_URI\"] = \"uri\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"password\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be9a202f-ca8d-4af8-809e-954824709723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_27872\\105655917.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")  # 384 dimensions\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neo4j Graph and Vector setup\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "graph = Neo4jGraph()\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")  # 384 dimensions\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "\n",
    "# Ensure entity index exists\n",
    "graph.query(\"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11222d7c-f163-4aac-a91c-653ba69bea21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    }
   ],
   "source": [
    "# Data loading and preparation\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load documents from Wikipedia\n",
    "raw_documents = WikipediaLoader(query=\"Elizabeth I\").load()\n",
    "\n",
    "# Split documents into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=24)\n",
    "documents = text_splitter.split_documents(raw_documents[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59c2227-bf20-48fd-ae90-be5710a29dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM initialization\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# Convert documents to graph format\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "\n",
    "# Add documents to the graph\n",
    "graph.add_graph_documents(graph_documents, baseEntityLabel=True, include_source=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "847cacea-1c60-4b4c-8c16-cb441c79460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "# Define entity extraction schema\n",
    "class Entities(BaseModel):\n",
    "    names: List[str] = Field(..., description=\"Extracted entities from the text.\")\n",
    "\n",
    "# Create prompt for entity extraction\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are extracting organization and person entities from the text.\"),\n",
    "    (\"human\", \"Use the given format to extract information from the following input: {question}\")\n",
    "])\n",
    "\n",
    "entity_chain = prompt | llm.with_structured_output(Entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "540560cf-851f-4a60-a132-1cbdd16c6976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elizabeth I - QUEEN_OF -> England\n",
      "Elizabeth I - QUEEN_OF -> Ireland\n",
      "Elizabeth I - LAST_MONARCH_OF -> House Of Tudor\n",
      "Elizabeth I - CHILD_OF -> Anne Boleyn\n",
      "Elizabeth I - CHILD_OF -> Henry VIII\n",
      "Elizabeth I - CHILD_OF -> Henry VIII of England\n",
      "Elizabeth I - ESTABLISHED -> Church of England\n",
      "Elizabeth I - SUCCEEDED_BY -> James VI of Scotland\n",
      "Elizabeth I - SUCCEEDED_BY -> House of Stuart\n",
      "Elizabeth I - BORN_IN -> Greenwich Palace\n",
      "Elizabeth I - SUCCESSION -> James Vi Of Scotland\n",
      "Elizabeth I - SUBJECT_OF_DEBATE -> Norfolk Conspiracy\n",
      "Elizabeth I - SUBJECT_OF_DEBATE -> Elizabethan Exclusion\n",
      "Elizabeth I - AVOIDED -> Order Of Succession\n",
      "Elizabeth I - CONCERNED_WITH -> Scotland\n",
      "Elizabeth I - REJECTED -> Catholic Women\n",
      "Elizabeth I - OUTLIVED -> Edward Vi\n",
      "Elizabeth I - OUTLIVED -> Mary I\n",
      "Elizabeth I - OUTLIVED -> Jane Grey\n",
      "Elizabeth I - OUTLIVED -> Katherine Grey\n",
      "Elizabeth I - OUTLIVED -> Mary Grey\n",
      "Elizabeth I - OUTLIVED -> Margaret Clifford\n",
      "Elizabeth I - SUCCESSOR -> James Vi Of Scotland\n",
      "Elizabeth I - MOTHER -> Mary I\n",
      "Elizabeth I - MOTHER -> Anne of Cleves\n",
      "Elizabeth I - RULED -> England\n",
      "Elizabeth I - RULED -> Ireland\n",
      "Elizabeth I - RULED -> kingdom\n",
      "Elizabeth I - FROM_HOUSE -> House of Tudor\n",
      "Elizabeth I - HALF_SIBLING_OF -> Mary I\n",
      "Elizabeth I - HALF_SIBLING_OF -> Edward VI\n",
      "Elizabeth I - ADVISED_BY -> William Cecil\n",
      "Elizabeth I - ADVISED_BY -> John Dee\n",
      "Elizabeth I - ADVISED_BY -> Nicholas Bacon\n",
      "Elizabeth I - RAN_SECRET_SERVICE_WITH_HELP_OF -> Sir Francis Walsingham\n",
      "Elizabeth I - NAMED_AFTER -> Lady Elizabeth Howard\n",
      "Elizabeth I - NAMED_AFTER -> Elizabeth of York\n",
      "Elizabeth I - SUCCESSION_QUESTION -> James VI of Scotland\n",
      "Elizabeth I - FATHER -> Henry VIII\n",
      "Elizabeth I - LONGEST_REIGNING -> House of Tudor\n",
      "Elizabeth I - CORONATION_LOCATION -> Westminster Abbey, London\n",
      "Elizabeth I - CORONATION_LOCATION -> Westminster Abbey\n",
      "Elizabeth I - CORONATION_LOCATION -> Tower of London\n",
      "Elizabeth I - CORONATION_LOCATION -> Palace of Westminster\n",
      "Elizabeth I - CORONATION_LOCATION -> Westminster Hall\n",
      "Elizabeth I - CORONATED_ON -> 15 January 1559\n",
      "Elizabeth I - ASCENDED_THRONE_ON -> 17 November 1558\n",
      "Elizabeth I - INTENDED_TO -> restore England to Protestantism\n",
      "Elizabeth I - ALLOWED -> continuation of some Catholic customs\n",
      "Elizabeth I - DIED_IN -> 1603\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "\n",
    "# Generate full-text query for Neo4j\n",
    "def generate_full_text_query(input: str) -> str:\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    return \" AND \".join([f\"{word}~2\" for word in words])\n",
    "\n",
    "# Structured data retrieval\n",
    "def structured_retriever(question: str) -> str:\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke({\"question\": question})\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\"\"\",\n",
    "            {\"query\": generate_full_text_query(entity)},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result\n",
    "print(structured_retriever(\"Who is Elizabeth I?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8cc1aab-59b7-4aa6-9354-cf56d80a5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate structured and unstructured retrieval\n",
    "def retriever(question: str) -> str:\n",
    "    structured_data = structured_retriever(question)\n",
    "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
    "    return f\"\"\"Structured data:\n",
    "{structured_data}\n",
    "Unstructured data:\n",
    "{\"#Document \".join(unstructured_data)}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02b65302-6cbf-4095-8c7e-82ee7684e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.runnables import RunnableBranch, RunnableLambda, RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Format chat history for follow-up questions\n",
    "def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    return buffer\n",
    "\n",
    "# Question condensing\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following conversation and a follow-up question, rephrase the follow-up question to be standalone.\n",
    "    Chat History:\n",
    "    {chat_history}\n",
    "    Follow Up Input: {question}\n",
    "    Standalone question:\"\"\"\n",
    ")\n",
    "\n",
    "# Define search query processing\n",
    "_search_query = RunnableBranch(\n",
    "    (\n",
    "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(run_name=\"HasChatHistoryCheck\"),\n",
    "        RunnablePassthrough.assign(chat_history=lambda x: _format_chat_history(x[\"chat_history\"]))\n",
    "        | CONDENSE_QUESTION_PROMPT\n",
    "        | ChatOpenAI(temperature=0)\n",
    "        | StrOutputParser(),\n",
    "    ),\n",
    "    RunnableLambda(lambda x: x[\"question\"]),\n",
    ")\n",
    "\n",
    "# Combine search results into final answer\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel({\n",
    "        \"context\": _search_query | retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    })\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d62a1319-b22e-401b-98e4-ae5fa25ad33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_27872\\1015459617.py:5: LangChainDeprecationWarning: The function `remove_lucene_chars` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the function exists in the :meth:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :meth:`~langchain-neo4j` and import as `from :meth:`~langchain_neo4j.vectorstores.neo4j_vector import remove_lucene_chars``.\n",
      "  words = [el for el in remove_lucene_chars(input).split() if el]\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elizabeth I belonged to the House of Tudor.\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "print(chain.invoke({\"question\": \"Which house did Elizabeth I belong to?\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b55d809-88e7-459b-91ec-439eb519a014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elizabeth's younger brother was Edward VI.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"question\": \"Who was Elizabeth younger brother?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7306e-846f-4ab8-87c6-9405b5959576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
